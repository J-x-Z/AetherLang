// Tensor Library for AetherLang
// N-dimensional array with shape tracking and broadcasting support
//
// Design Goals:
// 1. Compile-time shape checking via const generics
// 2. CPU/GPU unified interface
// 3. Broadcasting rules (NumPy-compatible)
// 4. BLAS/cuBLAS acceleration

extern "C" {
    fn malloc(size: u64) -> *u8;
    fn free(ptr: *u8);
    fn memcpy(dst: *u8, src: *u8, n: u64) -> *u8;
    fn memset(dst: *u8, c: i32, n: u64) -> *u8;
}

// ==================== Device Enum ====================

pub const DEVICE_CPU: i32 = 0
pub const DEVICE_CUDA: i32 = 1

// ==================== Tensor Core Structure ====================

/// N-dimensional tensor with compile-time rank
/// T = element type (f32, f64, i32, etc.)
/// N = number of dimensions (const generic)
pub struct Tensor<T, const N: usize> {
    pub data: *T,           // Data pointer (CPU or GPU memory)
    pub shape: [u64; N],    // Shape of each dimension
    pub strides: [u64; N],  // Strides for indexing
    pub len: u64,           // Total number of elements
    pub device: i32,        // DEVICE_CPU or DEVICE_CUDA
    pub owns_data: bool,    // Whether to free data on drop
}

// ==================== Shape Utilities ====================

/// Calculate total elements from shape
pub fn shape_numel(shape: *u64, ndim: u64) -> u64 {
    let mut total: u64 = 1;
    let mut i: u64 = 0;
    while i < ndim {
        let dim: u64 = *((shape as u64 + i * 8) as *u64);
        total = total * dim;
        i = i + 1;
    }
    return total;
}

/// Calculate row-major strides from shape
pub fn shape_to_strides(shape: *u64, strides: *u64, ndim: u64) {
    if ndim == 0 {
        return;
    }
    let mut i: u64 = ndim - 1;
    let mut stride: u64 = 1;
    loop {
        *((strides as u64 + i * 8) as *u64) = stride;
        let dim: u64 = *((shape as u64 + i * 8) as *u64);
        stride = stride * dim;
        if i == 0 {
            break;
        }
        i = i - 1;
    }
}

// ==================== 1D Tensor (Vector) ====================

pub type Vector<T> = Tensor<T, 1>

impl Vector<f32> {
    /// Create a new 1D tensor filled with zeros
    pub fn zeros(len: u64) -> Vector<f32> {
        let size: u64 = len * 4;  // sizeof(f32) = 4
        let data: *f32 = malloc(size) as *f32;
        memset(data as *u8, 0, size);
        return Tensor {
            data: data,
            shape: [len],
            strides: [1],
            len: len,
            device: DEVICE_CPU,
            owns_data: true,
        };
    }

    /// Create a new 1D tensor filled with ones
    pub fn ones(len: u64) -> Vector<f32> {
        let size: u64 = len * 4;
        let data: *f32 = malloc(size) as *f32;
        let mut i: u64 = 0;
        while i < len {
            *((data as u64 + i * 4) as *f32) = 1.0;
            i = i + 1;
        }
        return Tensor {
            data: data,
            shape: [len],
            strides: [1],
            len: len,
            device: DEVICE_CPU,
            owns_data: true,
        };
    }

    /// Create from raw data (does not take ownership)
    pub fn from_ptr(data: *f32, len: u64) -> Vector<f32> {
        return Tensor {
            data: data,
            shape: [len],
            strides: [1],
            len: len,
            device: DEVICE_CPU,
            owns_data: false,
        };
    }

    /// Get element at index
    pub fn get(self: *Vector<f32>, i: u64) -> f32 {
        return *(((*self).data as u64 + i * 4) as *f32);
    }

    /// Set element at index
    pub fn set(self: *Vector<f32>, i: u64, value: f32) {
        *(((*self).data as u64 + i * 4) as *f32) = value;
    }

    /// Dot product with another vector
    pub fn dot(self: *Vector<f32>, other: *Vector<f32>) -> f32 {
        let mut sum: f32 = 0.0;
        let mut i: u64 = 0;
        while i < (*self).len {
            let a: f32 = *(((*self).data as u64 + i * 4) as *f32);
            let b: f32 = *(((*other).data as u64 + i * 4) as *f32);
            sum = sum + a * b;
            i = i + 1;
        }
        return sum;
    }

    /// Scale by scalar: self = alpha * self
    pub fn scale(self: *Vector<f32>, alpha: f32) {
        let mut i: u64 = 0;
        while i < (*self).len {
            let ptr: *f32 = ((*self).data as u64 + i * 4) as *f32;
            *ptr = *ptr * alpha;
            i = i + 1;
        }
    }

    /// Free memory (if owned)
    pub fn drop(self: *Vector<f32>) {
        if (*self).owns_data {
            free((*self).data as *u8);
        }
    }
}

// ==================== 2D Tensor (Matrix) ====================

pub type Matrix<T> = Tensor<T, 2>

impl Matrix<f32> {
    /// Create a new 2D tensor filled with zeros
    pub fn zeros(rows: u64, cols: u64) -> Matrix<f32> {
        let len: u64 = rows * cols;
        let size: u64 = len * 4;
        let data: *f32 = malloc(size) as *f32;
        memset(data as *u8, 0, size);
        return Tensor {
            data: data,
            shape: [rows, cols],
            strides: [cols, 1],
            len: len,
            device: DEVICE_CPU,
            owns_data: true,
        };
    }

    /// Create identity matrix
    pub fn eye(n: u64) -> Matrix<f32> {
        let mut m: Matrix<f32> = Matrix::zeros(n, n);
        let mut i: u64 = 0;
        while i < n {
            m.set(i, i, 1.0);
            i = i + 1;
        }
        return m;
    }

    /// Get element at (row, col)
    pub fn get(self: *Matrix<f32>, row: u64, col: u64) -> f32 {
        let idx: u64 = row * (*self).strides[0] + col * (*self).strides[1];
        return *(((*self).data as u64 + idx * 4) as *f32);
    }

    /// Set element at (row, col)
    pub fn set(self: *Matrix<f32>, row: u64, col: u64, value: f32) {
        let idx: u64 = row * (*self).strides[0] + col * (*self).strides[1];
        *(((*self).data as u64 + idx * 4) as *f32) = value;
    }

    /// Matrix multiplication: C = self @ other
    pub fn matmul(self: *Matrix<f32>, other: *Matrix<f32>) -> Matrix<f32> {
        let m: u64 = (*self).shape[0];
        let k: u64 = (*self).shape[1];
        let n: u64 = (*other).shape[1];

        let mut result: Matrix<f32> = Matrix::zeros(m, n);

        let mut i: u64 = 0;
        while i < m {
            let mut j: u64 = 0;
            while j < n {
                let mut sum: f32 = 0.0;
                let mut l: u64 = 0;
                while l < k {
                    let a: f32 = (*self).get(i, l);
                    let b: f32 = (*other).get(l, j);
                    sum = sum + a * b;
                    l = l + 1;
                }
                result.set(i, j, sum);
                j = j + 1;
            }
            i = i + 1;
        }
        return result;
    }

    /// Transpose (returns new matrix)
    pub fn transpose(self: *Matrix<f32>) -> Matrix<f32> {
        let rows: u64 = (*self).shape[0];
        let cols: u64 = (*self).shape[1];
        let mut result: Matrix<f32> = Matrix::zeros(cols, rows);
        let mut i: u64 = 0;
        while i < rows {
            let mut j: u64 = 0;
            while j < cols {
                let val: f32 = (*self).get(i, j);
                result.set(j, i, val);
                j = j + 1;
            }
            i = i + 1;
        }
        return result;
    }

    /// Free memory (if owned)
    pub fn drop(self: *Matrix<f32>) {
        if (*self).owns_data {
            free((*self).data as *u8);
        }
    }
}

// ==================== Broadcasting ====================

/// Check if two shapes are broadcast-compatible
pub fn shapes_broadcast_compatible(
    shape_a: *u64, ndim_a: u64,
    shape_b: *u64, ndim_b: u64
) -> bool {
    let max_ndim: u64 = if ndim_a > ndim_b { ndim_a } else { ndim_b };
    let mut i: u64 = 0;
    while i < max_ndim {
        let dim_a: u64 = if i < ndim_a {
            *((shape_a as u64 + (ndim_a - 1 - i) * 8) as *u64)
        } else { 1 };
        let dim_b: u64 = if i < ndim_b {
            *((shape_b as u64 + (ndim_b - 1 - i) * 8) as *u64)
        } else { 1 };
        if dim_a != dim_b && dim_a != 1 && dim_b != 1 {
            return false;
        }
        i = i + 1;
    }
    return true;
}

// ==================== Activation Functions ====================

/// Apply ReLU element-wise: max(0, x)
pub fn relu_inplace(data: *f32, len: u64) {
    let mut i: u64 = 0;
    while i < len {
        let ptr: *f32 = (data as u64 + i * 4) as *f32;
        if *ptr < 0.0 {
            *ptr = 0.0;
        }
        i = i + 1;
    }
}

/// Apply Sigmoid element-wise (approximation)
pub fn sigmoid_inplace(data: *f32, len: u64) {
    let mut i: u64 = 0;
    while i < len {
        let ptr: *f32 = (data as u64 + i * 4) as *f32;
        let x: f32 = *ptr;
        let half_x: f32 = x * 0.5;
        let abs_x: f32 = if half_x < 0.0 { 0.0 - half_x } else { half_x };
        let tanh_approx: f32 = half_x / (1.0 + abs_x + half_x * half_x / 3.0);
        *ptr = 0.5 + 0.5 * tanh_approx;
        i = i + 1;
    }
}

fn main() {
    // Test Vector
    let mut v: Vector<f32> = Vector::zeros(4);
    v.set(0, 1.0);
    v.set(1, 2.0);

    // Test Matrix  
    let mut m: Matrix<f32> = Matrix::eye(3);

    v.drop();
    m.drop();
}
