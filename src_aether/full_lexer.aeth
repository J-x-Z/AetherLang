// AetherLang Standard Library: Core Module
// Provides low-level FFI bindings to C stdlib

extern "C" {
    fn malloc(size: u64) -> *u8;
    // fn free(ptr: *u8);  // Built-in
    fn realloc(ptr: *u8, new_size: u64) -> *u8;
    fn memcpy(dest: *u8, src: *u8, n: u64) -> *u8;
    fn memset(s: *u8, c: i32, n: u64) -> *u8;
    fn printf(fmt: *u8) -> i32;
    fn putchar(c: i32) -> i32;
    fn getchar() -> i32;
    // fn exit(status: i32);  // Built-in
    fn abort();
    fn strlen(s: *u8) -> u64;
    fn strcmp(s1: *u8, s2: *u8) -> i32;
    fn strcpy(dest: *u8, src: *u8) -> *u8;
    fn atof(nptr: *u8) -> f64;
}

pub fn my_println(s: *u8) {
    printf(s);
    putchar(10 as i32);
}

pub fn my_assert(cond: bool) {
    if !cond {
        exit(1 as i32);
    }
}

// ==================== String ====================
// AetherLang Standard Library: String Module
// Provides a heap-allocated, growable string type


/// A heap-allocated, growable UTF-8 string
pub struct String {
    /// Pointer to the string data (null-terminated for C compat)
    data: *u8,
    /// Length of the string (excluding null terminator)
    len: u64,
    /// Allocated capacity
    capacity: u64,
}

impl String {
    /// Create a new empty string
    pub fn new() -> String {
        let initial_cap: u64 = 16;
        let data: *u8 = malloc(initial_cap);
        // Null terminate
        *(data as *u8) = 0;
        
        String {
            data: data,
            len: 0,
            capacity: initial_cap,
        }
    }
    
    /// Create a string from a C string literal
    pub fn from_cstr(s: *u8) -> String {
        let src_len: u64 = strlen(s);
        let cap: u64 = src_len + 1;
        let data: *u8 = malloc(cap);
        memcpy(data, s, cap);
        
        String {
            data: data,
            len: src_len,
            capacity: cap,
        }
    }
    
    /// Get the length of the string
    pub fn len(self: &String) -> u64 {
        self.len
    }
    
    /// Check if the string is empty
    pub fn is_empty(self: &String) -> bool {
        self.len == 0
    }
    
    /// Get a pointer to the underlying C string
    pub fn as_ptr(self: &String) -> *u8 {
        self.data
    }
    
    /// Ensure the string has enough capacity for n more bytes
    fn ensure_capacity(self: &mut String, additional: u64) {
        let required: u64 = self.len + additional + 1;  // +1 for null
        if required > self.capacity {
            let new_cap: u64 = required * 2;
            self.data = realloc(self.data, new_cap);
            self.capacity = new_cap;
        }
    }
    
    /// Append a single byte/char to the string
    pub fn push(self: &mut String, c: u8) {
        self.ensure_capacity(1);
        // Set the character
        let ptr: *u8 = self.data + self.len;
        *ptr = c;
        self.len = self.len + 1;
        // Null terminate
        let end: *u8 = self.data + self.len;
        *end = 0;
    }
    
    /// Append another string
    pub fn push_str(self: &mut String, other: &String) {
        self.ensure_capacity(other.len);
        memcpy(self.data + self.len, other.data, other.len);
        self.len = self.len + other.len;
        // Null terminate
        let end: *u8 = self.data + self.len;
        *end = 0;
    }
    
    /// Clear the string
    pub fn clear(self: &mut String) {
        self.len = 0;
        *(self.data) = 0;
    }
    
    /// Get character at index (no bounds checking)
    pub fn char_at(self: &String, idx: u64) -> u8 {
        let ptr: *u8 = self.data + idx;
        *ptr

    }
    
    /// Print the string to stdout
    pub fn print(self: &String) {
        printf(self.data);
    }
    /// Clone the string
    pub fn clone(self: &String) -> String {
        let mut s: String = String::new();
        s.push_str(self);
        s
    }
}

/// Drop implementation - free the allocated memory
impl Drop for String {
    fn drop(self: &mut String) {
        free(self.data);
    }
}

// ==================== Span ====================
// AetherLang Compiler: Span Module (Self-Hosted)
// Source location tracking

/// A source span (file, start, end positions)
pub struct Span {
    /// File ID (for multi-file compilation)
    pub file_id: u64,
    /// Start byte offset
    pub start: u64,
    /// End byte offset
    pub end: u64,
}

impl Span {
    /// Create a new span
    pub fn new(file_id: u64, start: u64, end: u64) -> Span {
        Span {
            file_id: file_id,
            start: start,
            end: end,
        }
    }
    
    /// Create an empty span at a position
    pub fn empty(file_id: u64, pos: u64) -> Span {
        Span {
            file_id: file_id,
            start: pos,
            end: pos,
        }
    }
    
    /// Merge two spans
    pub fn merge(self: &Span, other: &Span) -> Span {
        Span {
            file_id: self.file_id,
            start: if self.start < other.start { self.start } else { other.start },
            end: if self.end > other.end { self.end } else { other.end },
        }
    }
}

// ==================== Token ====================
// AetherLang Compiler: Token Module (Self-Hosted)
// Token definitions for the lexer


/// Token kind enumeration
pub enum TokenKind {
    // ============ Keywords ============
    Fn,
    Let,
    Mut,
    If,
    Else,
    Loop,
    While,
    For,
    In,
    Return,
    Match,
    Struct,
    Impl,
    Enum,
    Interface,
    Own,
    Ref,
    Const,
    Unsafe,
    Break,
    Continue,
    True,
    False,
    Asm,
    As,
    
    // AI-Native Keywords
    Type,
    Trait,
    Pub,
    Where,
    Shared,
    Pure,
    Effect,
    Requires,
    Ensures,
    Invariant,
    
    // System Keywords
    Extern,
    Static,
    Union,
    Volatile,
    
    // ============ Literals ============
    Ident(String),
    IntLit(i64),
    FloatLit(f64),
    StringLit(String),
    CharLit(u8),
    
    // ============ Operators ============
    Plus,       // +
    Minus,      // -
    Star,       // *
    Slash,      // /
    Percent,    // %
    Eq,         // =
    EqEq,       // ==
    Ne,         // !=
    Lt,         // <
    Le,         // <=
    Gt,         // >
    Ge,         // >=
    AndAnd,     // &&
    OrOr,       // ||
    Not,        // !
    And,        // &
    Or,         // |
    Caret,      // ^
    Shl,        // <<
    Shr,        // >>
    PlusEq,     // +=
    MinusEq,    // -=
    StarEq,     // *=
    SlashEq,    // /=
    ShrEq,      // >>=
    FatArrow,   // =>
    Arrow,      // ->
    Dot,        // .
    DotDot,     // ..
    ColonColon, // ::
    Question,   // ?
    
    // ============ Delimiters ============
    LParen,     // (
    RParen,     // )
    LBrace,     // {
    RBrace,     // }
    LBracket,   // [
    RBracket,   // ]
    Comma,      // ,
    Colon,      // :
    Semicolon,  // ;
    At,         // @
    Hash,       // #
    Tilde,      // ~
    
    // ============ Special ============
    Eof,
    Unknown(u8),
}

/// A token with its source span
pub struct Token {
    pub kind: TokenKind,
    pub span: Span,
}

impl Token {
    /// Create a new token
    pub fn new(kind: TokenKind, span: Span) -> Token {
        Token { kind: kind, span: span }
    }
    
    /// Create an EOF token
    pub fn eof(span: Span) -> Token {
        Token { kind: TokenKind::Eof, span: span }
    }
}

/// Helper to compare string with literal
fn strcmp_lit(s: *u8, lit: *u8) -> bool {
    // Uses C strcmp
    strcmp(s, lit) == 0
}
/// Check if an identifier is a keyword and return the token kind
pub fn keyword_from_str(s: &String) -> TokenKind {
    // This is a simplified version - in real code we'd use a hash map
    let ptr: *u8 = s.as_ptr();
    let len: u64 = s.len();
    
    // Check common keywords by length first
    if len == 2 {
        if strcmp_lit(ptr, "fn") { return TokenKind::Fn; }
        if strcmp_lit(ptr, "if") { return TokenKind::If; }
        if strcmp_lit(ptr, "in") { return TokenKind::In; }
        if strcmp_lit(ptr, "as") { return TokenKind::As; }
    }
    if len == 3 {
        if strcmp_lit(ptr, "let") { return TokenKind::Let; }
        if strcmp_lit(ptr, "mut") { return TokenKind::Mut; }
        if strcmp_lit(ptr, "for") { return TokenKind::For; }
        if strcmp_lit(ptr, "ref") { return TokenKind::Ref; }
        if strcmp_lit(ptr, "own") { return TokenKind::Own; }
        if strcmp_lit(ptr, "asm") { return TokenKind::Asm; }
        if strcmp_lit(ptr, "pub") { return TokenKind::Pub; }
    }
    if len == 4 {
        if strcmp_lit(ptr, "else") { return TokenKind::Else; }
        if strcmp_lit(ptr, "loop") { return TokenKind::Loop; }
        if strcmp_lit(ptr, "true") { return TokenKind::True; }
        if strcmp_lit(ptr, "enum") { return TokenKind::Enum; }
        if strcmp_lit(ptr, "impl") { return TokenKind::Impl; }
        if strcmp_lit(ptr, "type") { return TokenKind::Type; }
        if strcmp_lit(ptr, "pure") { return TokenKind::Pure; }
    }
    if len == 5 {
        if strcmp_lit(ptr, "while") { return TokenKind::While; }
        if strcmp_lit(ptr, "match") { return TokenKind::Match; }
        if strcmp_lit(ptr, "break") { return TokenKind::Break; }
        if strcmp_lit(ptr, "false") { return TokenKind::False; }
        if strcmp_lit(ptr, "const") { return TokenKind::Const; }
        if strcmp_lit(ptr, "trait") { return TokenKind::Trait; }
        if strcmp_lit(ptr, "where") { return TokenKind::Where; }
        if strcmp_lit(ptr, "union") { return TokenKind::Union; }
    }
    if len == 6 {
        if strcmp_lit(ptr, "return") { return TokenKind::Return; }
        if strcmp_lit(ptr, "struct") { return TokenKind::Struct; }
        if strcmp_lit(ptr, "unsafe") { return TokenKind::Unsafe; }
        if strcmp_lit(ptr, "extern") { return TokenKind::Extern; }
        if strcmp_lit(ptr, "static") { return TokenKind::Static; }
        if strcmp_lit(ptr, "effect") { return TokenKind::Effect; }
        if strcmp_lit(ptr, "shared") { return TokenKind::Shared; }
    }
    if len == 7 {
        if strcmp_lit(ptr, "ensures") { return TokenKind::Ensures; }
    }
    if len == 8 {
        if strcmp_lit(ptr, "continue") { return TokenKind::Continue; }
        if strcmp_lit(ptr, "requires") { return TokenKind::Requires; }
        if strcmp_lit(ptr, "volatile") { return TokenKind::Volatile; }
    }
    if len == 9 {
        if strcmp_lit(ptr, "interface") { return TokenKind::Interface; }
        if strcmp_lit(ptr, "invariant") { return TokenKind::Invariant; }
    }
    
    // Not a keyword, return as identifier
    TokenKind::Ident(s.clone())
}


// ==================== VecToken ====================
// AetherLang Standard Library: Vec Module
// Provides a heap-allocated, growable array type


/// A heap-allocated, growable array
pub struct VecToken {
    /// Pointer to the array data
    data: *Token,
    /// Number of elements
    len: u64,
    /// Allocated capacity (in elements)
    capacity: u64,
}

impl VecToken {
    /// Create a new empty vector
    pub fn new() -> VecToken {
        VecToken {
            data: 0 as *Token,  // null pointer
            len: 0,
            capacity: 0,
        }
    }
    
    /// Create a vector with pre-allocated capacity
    pub fn with_capacity(cap: u64) -> VecToken {
        let elem_size: u64 = 64;  // TODO: sizeof<T>
        let data: *Token = malloc(cap * elem_size) as *Token;
        
        VecToken {
            data: data,
            len: 0,
            capacity: cap,
        }
    }
    
    /// Get the number of elements
    pub fn len(self: &VecToken) -> u64 {
        self.len
    }
    
    /// Check if empty
    pub fn is_empty(self: &VecToken) -> bool {
        self.len == 0
    }
    
    /// Get the capacity
    pub fn capacity(self: &VecToken) -> u64 {
        self.capacity
    }
    
    /// Ensure capacity for n more elements
    fn ensure_capacity(self: &mut VecToken, additional: u64) {
        let required: u64 = self.len + additional;
        if required > self.capacity {
            let new_cap: u64 = if self.capacity == 0 { 8 as u64 } else { self.capacity * (2 as u64) };
            let final_cap: u64 = if new_cap < required { required } else { new_cap };
            
            let elem_size: u64 = 64;  // TODO: sizeof<T>
            let new_data: *Token = malloc(final_cap * elem_size) as *Token;
            
            if self.len > 0 {
                memcpy(new_data as *u8, self.data as *u8, self.len * elem_size);
            }
            
            if self.capacity > 0 {
                free(self.data as *u8);
            }
            
            self.data = new_data;
            self.capacity = final_cap;
        }
    }
    
    /// Push an element to the end
    pub fn push(self: &mut VecToken, value: Token) {
        self.ensure_capacity(1);
        let ptr: *Token = self.data + self.len;
        *ptr = value;
        self.len = self.len + 1;
    }
    
    /// Pop the last element
    pub fn pop(self: &mut VecToken) -> Token {
        // TODO: Return Option<T>
        self.len = self.len - 1;
        let ptr: *Token = self.data + self.len;
        *ptr
    }
    
    /// Get element at index (no bounds checking)
    pub fn get(self: &VecToken, idx: u64) -> &Token {
        let ptr: *Token = self.data + idx;
        &(*ptr)
    }
    
    /// Get mutable element at index
    pub fn get_mut(self: &mut VecToken, idx: u64) -> &mut Token {
        let ptr: *Token = self.data + idx;
        &mut (*ptr)
    }
    
    /// Clear the vector
    pub fn clear(self: &mut VecToken) {
        self.len = 0;
    }
}

/// Drop implementation
impl Drop for VecToken {
    fn drop(self: &mut VecToken) {
        if self.capacity > 0 {
            free(self.data as *u8);
        }
    }
}

// ==================== Lexer ====================
// AetherLang Compiler: Lexer Module (Self-Hosted)
// Converts source code into a stream of tokens


/// The lexer state
pub struct Lexer {
    /// Source code as bytes
    source: *u8,
    /// Source length
    source_len: u64,
    /// Current position in source
    pos: u64,
    /// Start position of current token
    start: u64,
    /// File ID for span tracking
    file_id: u64,
}

impl Lexer {
    /// Create a new lexer for the given source code
    pub fn new(source: *u8, source_len: u64, file_id: u64) -> Lexer {
        Lexer {
            source: source,
            source_len: source_len,
            pos: 0,
            start: 0,
            file_id: file_id,
        }
    }
    
    /// Get the current character without advancing
    fn peek(self: &Lexer) -> u8 {
        if self.pos >= self.source_len {
            return 0;  // null = EOF
        }
        let ptr: *u8 = self.source + self.pos;
        *ptr
    }
    
    /// Get the next character without advancing
    fn peek_next(self: &Lexer) -> u8 {
        if self.pos + 1 >= self.source_len {
            return 0;
        }
        let ptr: *u8 = self.source + self.pos + 1;
        *ptr
    }
    
    /// Advance to the next character
    fn advance(self: &mut Lexer) -> u8 {
        let c: u8 = self.peek();
        self.pos = self.pos + 1;
        c
    }
    
    /// Check if we've reached the end of input
    fn is_at_end(self: &Lexer) -> bool {
        self.pos >= self.source_len
    }
    
    /// Create a span from start to current position
    fn make_span(self: &Lexer) -> Span {
        Span { file_id: self.file_id, start: self.start, end: self.pos }
    }
    
    /// Create a token with the current span
    fn make_token(self: &Lexer, kind: TokenKind) -> Token {
        Token { kind: kind, span: self.make_span() }
    }
    
    /// Check if character is alphabetic
    fn is_alpha(c: u8) -> bool {
        (c >= 65 && c <= 90) || (c >= 97 && c <= 122) || c == 95  // A-Z, a-z, _
    }
    
    /// Check if character is digit
    fn is_digit(c: u8) -> bool {
        c >= 48 && c <= 57  // 0-9
    }
    
    /// Check if character is alphanumeric
    fn is_alnum(c: u8) -> bool {
        Lexer::is_alpha(c) || Lexer::is_digit(c)
    }
    
    /// Check if character is whitespace
    fn is_whitespace(c: u8) -> bool {
        c == 32 || c == 9 || c == 10 || c == 13  // space, tab, newline, carriage return
    }
    
    /// Skip whitespace and comments
    fn skip_whitespace(self: &mut Lexer) {
        loop {
            let c: u8 = self.peek();
            
            // Whitespace
            if Lexer::is_whitespace(c) {
                self.advance();
            }
            // Line comment //
            else if c == 47 && self.peek_next() == 47 {
                // Skip until end of line
                while !self.is_at_end() && self.peek() != 10 {
                    self.advance();
                }
            }
            // Block comment /* */
            else if c == 47 && self.peek_next() == 42 {
                self.advance();  // skip /
                self.advance();  // skip *
                let mut depth: i32 = 1;
                while depth > 0 && !self.is_at_end() {
                    let c1: u8 = self.peek();
                    let c2: u8 = self.peek_next();
                    if c1 == 42 && c2 == 47 {  // */
                        self.advance();
                        self.advance();
                        depth = depth - 1;
                    } else if c1 == 47 && c2 == 42 {  // /*
                        self.advance();
                        self.advance();
                        depth = depth + 1;
                    } else {
                        self.advance();
                    }
                }
            }
            else {
                break;
            }
        }
    }
    
    /// Read an identifier or keyword
    fn read_identifier(self: &mut Lexer) -> Token {
        while Lexer::is_alnum(self.peek()) {
            self.advance();
        }
        
        // Build the identifier string
        let len: u64 = self.pos - self.start;
        let mut s: String = String::new();
        let mut i: u64 = 0;
        while i < len {
            let ptr: *u8 = self.source + self.start + i;
            s.push(*ptr);
            i = i + 1;
        }
        
        // Check if it's a keyword
        let kind: TokenKind = keyword_from_str(&s);
        self.make_token(kind)
    }
    
    /// Read a number literal (integer or float)
    fn read_number(self: &mut Lexer) -> Token {
        let mut is_float: bool = false;
        
        // Check for hex literal 0x
        if self.peek() == 48 && (self.peek_next() == 120 || self.peek_next() == 88) {
            self.advance();  // 0
            self.advance();  // x
            
            while Lexer::is_hex_digit(self.peek()) || self.peek() == 95 {
                self.advance();
            }
            
            // Parse hex value
            let value: i64 = self.parse_hex();
            return self.make_token(TokenKind::IntLit(value));
        }
        
        // Regular decimal number
        while Lexer::is_digit(self.peek()) || self.peek() == 95 {
            self.advance();
        }
        
        // Check for decimal point
        if self.peek() == 46 && Lexer::is_digit(self.peek_next()) {
            is_float = true;
            self.advance();  // consume '.'
            
            while Lexer::is_digit(self.peek()) || self.peek() == 95 {
                self.advance();
            }
        }
        
        // Check for exponent
        if self.peek() == 101 || self.peek() == 69 {  // e or E
            is_float = true;
            self.advance();
            
            if self.peek() == 43 || self.peek() == 45 {  // + or -
                self.advance();
            }
            
            while Lexer::is_digit(self.peek()) {
                self.advance();
            }
        }
        
        if is_float {
            let value: f64 = self.parse_float();
            self.make_token(TokenKind::FloatLit(value))
        } else {
            let value: i64 = self.parse_int();
            self.make_token(TokenKind::IntLit(value))
        }
    }
    
    /// Check if hex digit
    fn is_hex_digit(c: u8) -> bool {
        Lexer::is_digit(c) || (c >= 65 && c <= 70) || (c >= 97 && c <= 102)
    }
    
    /// Parse integer from current token range
    fn parse_int(self: &Lexer) -> i64 {
        let mut value: i64 = 0;
        let mut i: u64 = self.start;
        while i < self.pos {
            let c: u8 = *(self.source + i);
            if c != 95 {  // skip underscores
                value = value * 10 + (c - 48) as i64;
            }
            i = i + 1;
        }
        value
    }
    
    /// Parse hex integer
    fn parse_hex(self: &Lexer) -> i64 {
        let mut value: i64 = 0;
        let mut i: u64 = self.start + 2;  // skip 0x
        while i < self.pos {
            let c: u8 = *(self.source + i);
            if c != 95 {
                let digit: i64 = if c >= 48 && c <= 57 {
                    (c - 48) as i64
                } else if c >= 65 && c <= 70 {
                    (c - 55) as i64  // A=10
                } else {
                    (c - 87) as i64  // a=10
                };
                value = value * 16 + digit;
            }
            i = i + 1;
        }
        value
    }
    
    /// Parse float (simplified)
    fn parse_float(self: &Lexer) -> f64 {
        // TODO: Proper float parsing
        
        // Build null-terminated string
        let len: u64 = self.pos - self.start;
        let buf: *u8 = malloc(len + 1);
        let mut j: u64 = 0;
        let mut i: u64 = self.start;
        while i < self.pos {
            let c: u8 = *(self.source + i);
            if c != 95 {
                *(buf + j) = c;
                j = j + 1;
            }
            i = i + 1;
        }
        // 添加分号防止 while * 歧义
        ;
        *(buf + j) = 0;
        
        let result: f64 = atof(buf);
        free(buf);
        result
    }
    
    /// Read a string literal
    fn read_string(self: &mut Lexer) -> Token {
        self.advance();  // consume opening quote
        
        let mut value: String = String::new();
        
        while !self.is_at_end() {
            let c: u8 = self.peek();
            
            if c == 34 {  // closing quote
                self.advance();
                break;
            } else if c == 92 {  // backslash escape
                self.advance();
                let esc: u8 = self.peek();
                if esc == 110 { value.push(10); self.advance(); }       // \n
                else if esc == 114 { value.push(13); self.advance(); }  // \r
                else if esc == 116 { value.push(9); self.advance(); }   // \t
                else if esc == 92 { value.push(92); self.advance(); }   // \\
                else if esc == 34 { value.push(34); self.advance(); }   // \"
                else if esc == 48 { value.push(0); self.advance(); }    // \0
                else { value.push(esc); self.advance(); }
            } else if c == 10 {  // newline - unterminated string
                break;
            } else {
                value.push(c);
                self.advance();
            }
        }
        
        self.make_token(TokenKind::StringLit(value))
    }
    
    /// Read a character literal
    fn read_char(self: &mut Lexer) -> Token {
        self.advance();  // consume opening quote
        
        let c: u8 = if self.peek() == 92 {  // backslash
            self.advance();
            let esc: u8 = self.peek();
            self.advance();
            if esc == 110 { 10 }       // \n
            else if esc == 114 { 13 }  // \r
            else if esc == 116 { 9 }   // \t
            else if esc == 92 { 92 }   // \\
            else if esc == 39 { 39 }   // \'
            else if esc == 48 { 0 }    // \0
            else { esc }
        } else {
            self.advance()
        };
        
        // Consume closing quote
        if self.peek() == 39 {
            self.advance();
        }
        
        self.make_token(TokenKind::CharLit(c))
    }
    
    /// Match operator tokens
    fn match_operator(self: &mut Lexer, c: u8) -> TokenKind {
        if c == 43 {  // +
            if self.peek() == 61 { self.advance(); return TokenKind::PlusEq; }
            return TokenKind::Plus;
        }
        if c == 45 {  // -
            if self.peek() == 62 { self.advance(); return TokenKind::Arrow; }
            if self.peek() == 61 { self.advance(); return TokenKind::MinusEq; }
            return TokenKind::Minus;
        }
        if c == 42 {  // *
            if self.peek() == 61 { self.advance(); return TokenKind::StarEq; }
            return TokenKind::Star;
        }
        if c == 47 {  // /
            if self.peek() == 61 { self.advance(); return TokenKind::SlashEq; }
            return TokenKind::Slash;
        }
        if c == 37 { return TokenKind::Percent; }  // %
        if c == 61 {  // =
            if self.peek() == 61 { self.advance(); return TokenKind::EqEq; }
            if self.peek() == 62 { self.advance(); return TokenKind::FatArrow; }
            return TokenKind::Eq;
        }
        if c == 33 {  // !
            if self.peek() == 61 { self.advance(); return TokenKind::Ne; }
            return TokenKind::Not;
        }
        if c == 60 {  // <
            if self.peek() == 61 { self.advance(); return TokenKind::Le; }
            if self.peek() == 60 { self.advance(); return TokenKind::Shl; }
            return TokenKind::Lt;
        }
        if c == 62 {  // >
            if self.peek() == 61 { self.advance(); return TokenKind::Ge; }
            if self.peek() == 62 { self.advance(); return TokenKind::Shr; }
            return TokenKind::Gt;
        }
        if c == 38 {  // &
            if self.peek() == 38 { self.advance(); return TokenKind::AndAnd; }
            return TokenKind::And;
        }
        if c == 124 {  // |
            if self.peek() == 124 { self.advance(); return TokenKind::OrOr; }
            return TokenKind::Or;
        }
        if c == 94 { return TokenKind::Caret; }  // ^
        if c == 46 {  // .
            if self.peek() == 46 { self.advance(); return TokenKind::DotDot; }
            return TokenKind::Dot;
        }
        if c == 58 {  // :
            if self.peek() == 58 { self.advance(); return TokenKind::ColonColon; }
            return TokenKind::Colon;
        }
        if c == 40 { return TokenKind::LParen; }   // (
        if c == 41 { return TokenKind::RParen; }   // )
        if c == 123 { return TokenKind::LBrace; }  // {
        if c == 125 { return TokenKind::RBrace; }  // }
        if c == 91 { return TokenKind::LBracket; } // [
        if c == 93 { return TokenKind::RBracket; } // ]
        if c == 44 { return TokenKind::Comma; }    // ,
        if c == 59 { return TokenKind::Semicolon; } // ;
        if c == 64 { return TokenKind::At; }       // @
        if c == 35 { return TokenKind::Hash; }     // #
        if c == 63 { return TokenKind::Question; } // ?
        if c == 126 { return TokenKind::Tilde; }   // ~
        
        TokenKind::Unknown(c)
    }
    
    /// Get the next token
    pub fn next_token(self: &mut Lexer) -> Token {
        self.skip_whitespace();
        self.start = self.pos;
        
        if self.is_at_end() {
            return Token::eof(self.make_span());
        }
        
        let c: u8 = self.advance();
        
        // Identifiers and keywords
        if Lexer::is_alpha(c) {
            self.pos = self.pos - 1;  // back up
            return self.read_identifier();
        }
        
        // Numbers
        if Lexer::is_digit(c) {
            self.pos = self.pos - 1;
            return self.read_number();
        }
        
        // String literals
        if c == 34 {  // "
            self.pos = self.pos - 1;
            return self.read_string();
        }
        
        // Character literals
        if c == 39 {  // '
            self.pos = self.pos - 1;
            return self.read_char();
        }
        
        // Operators and punctuation
        let kind: TokenKind = self.match_operator(c);
        self.make_token(kind)
    }
    
    /// Tokenize the entire source and return all tokens
    pub fn tokenize(self: &mut Lexer) -> VecToken {
        let mut tokens: VecToken = VecToken::new();
        let mut count: u64 = 0;
        // Simplified: tokenize up to 1000 tokens max
        while count < 1000 {
            let token: Token = self.next_token();
            tokens.push(token);
            count = count + 1;
            // Check if at end of source
            if self.pos >= self.source_len {
                break;
            }
        }
        tokens
    }
}

// ==================== Test ====================
// AetherLang Lexer Test Harness
// Tests the self-hosted lexer by tokenizing a simple source file


/// Entry point
fn main() {
    // Simple test
    printf("Hello from Lexer!\n");
}

// TODO: Fix match with enum variant patterns - currently causes LLVM codegen issues
// /// Print a single token
// fn print_token(tok: &Token) {
//     let kind_name: *u8 = match tok.kind {
//         TokenKind::Fn => "Fn",
//         TokenKind::Let => "Let",
//         TokenKind::Ident(_) => "Ident",
//         TokenKind::IntLit(_) => "IntLit",
//         TokenKind::StringLit(_) => "StringLit",
//         TokenKind::LParen => "LParen",
//         TokenKind::RParen => "RParen",
//         TokenKind::LBrace => "LBrace",
//         TokenKind::RBrace => "RBrace",
//         TokenKind::Semicolon => "Semicolon",
//         TokenKind::Eof => "Eof",
//         _ => "Other",
//     };
//     printf("  [%d-%d] %s\n", tok.span.start, tok.span.end, kind_name);
// }
