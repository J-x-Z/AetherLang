// AetherLang Lexer â†’ Parser Integration Test
// Tests token flow from lexer to parser

extern "C" {
    fn putchar(c: i32) -> i32;
    fn malloc(size: u64) -> *u8;
}

// ==================== Token ====================

pub enum TokenKind {
    IntLit,
    Ident,
    Fn,
    Let,
    Return,
    LParen,
    RParen,
    LBrace,
    RBrace,
    Colon,
    Arrow,
    Plus,
    Semicolon,
    Eof,
}

pub struct Token {
    pub kind: TokenKind,
    pub start: u64,
    pub len: u64,
    pub int_value: i64,
}

impl Token {
    pub fn new(kind: TokenKind, start: u64, len: u64) -> Token {
        return Token {
            kind: kind,
            start: start,
            len: len,
            int_value: 0,
        };
    }
    
    pub fn int(start: u64, len: u64, value: i64) -> Token {
        return Token {
            kind: TokenKind::IntLit,
            start: start,
            len: len,
            int_value: value,
        };
    }
}

// ==================== Lexer ====================

pub struct Lexer {
    pub source: *u8,
    pub len: u64,
    pub pos: u64,
}

impl Lexer {
    pub fn new(source: *u8, len: u64) -> Lexer {
        return Lexer {
            source: source,
            len: len,
            pos: 0,
        };
    }
    
    pub fn peek(self: &Lexer) -> u8 {
        if self.pos >= self.len {
            return 0;
        }
        let ptr: *u8 = (self.source as u64 + self.pos) as *u8;
        return *ptr;
    }
    
    pub fn advance(self: &mut Lexer) -> u8 {
        let c: u8 = self.peek();
        self.pos = self.pos + 1;
        return c;
    }
    
    pub fn skip_whitespace(self: &mut Lexer) {
        while self.pos < self.len {
            let c: u8 = self.peek();
            if c == 32 || c == 10 || c == 13 || c == 9 {
                self.advance();
            } else {
                return;
            }
        }
    }
    
    pub fn is_digit(c: u8) -> bool {
        return c >= 48 && c <= 57;
    }
    
    pub fn is_alpha(c: u8) -> bool {
        return (c >= 65 && c <= 90) || (c >= 97 && c <= 122) || c == 95;
    }
    
    pub fn next_token(self: &mut Lexer) -> Token {
        self.skip_whitespace();
        
        if self.pos >= self.len {
            return Token::new(TokenKind::Eof, self.pos, 0);
        }
        
        let start: u64 = self.pos;
        let c: u8 = self.advance();
        
        // Single char tokens
        if c == 40 { return Token::new(TokenKind::LParen, start, 1); }
        if c == 41 { return Token::new(TokenKind::RParen, start, 1); }
        if c == 123 { return Token::new(TokenKind::LBrace, start, 1); }
        if c == 125 { return Token::new(TokenKind::RBrace, start, 1); }
        if c == 58 { return Token::new(TokenKind::Colon, start, 1); }
        if c == 59 { return Token::new(TokenKind::Semicolon, start, 1); }
        if c == 43 { return Token::new(TokenKind::Plus, start, 1); }
        
        // Arrow: ->
        if c == 45 {
            if self.peek() == 62 {
                self.advance();
                return Token::new(TokenKind::Arrow, start, 2);
            }
        }
        
        // Number
        if Lexer::is_digit(c) {
            let mut value: i64 = (c - 48) as i64;
            while Lexer::is_digit(self.peek()) {
                value = value * 10 + (self.advance() - 48) as i64;
            }
            return Token::int(start, self.pos - start, value);
        }
        
        // Identifier or keyword
        if Lexer::is_alpha(c) {
            while Lexer::is_alpha(self.peek()) || Lexer::is_digit(self.peek()) {
                self.advance();
            }
            let len: u64 = self.pos - start;
            
            // Check keywords
            if len == 2 {
                let ptr: *u8 = (self.source as u64 + start) as *u8;
                let c0: u8 = *ptr;
                let c1: u8 = *((ptr as u64 + 1) as *u8);
                if c0 == 102 && c1 == 110 {  // 'fn'
                    return Token::new(TokenKind::Fn, start, len);
                }
            }
            if len == 3 {
                let ptr: *u8 = (self.source as u64 + start) as *u8;
                let c0: u8 = *ptr;
                let c1: u8 = *((ptr as u64 + 1) as *u8);
                let c2: u8 = *((ptr as u64 + 2) as *u8);
                if c0 == 108 && c1 == 101 && c2 == 116 {  // 'let'
                    return Token::new(TokenKind::Let, start, len);
                }
            }
            if len == 6 {
                let ptr: *u8 = (self.source as u64 + start) as *u8;
                let c0: u8 = *ptr;
                if c0 == 114 {  // 'return'
                    return Token::new(TokenKind::Return, start, len);
                }
            }
            
            return Token::new(TokenKind::Ident, start, len);
        }
        
        return Token::new(TokenKind::Eof, start, 0);
    }
}

// ==================== Main ====================

fn main() -> i32 {
    puts("=== Lexer Integration Test ===");
    puts("Source: fn main() { return 42; }");
    
    let source: *u8 = "fn main() { return 42; }" as *u8;
    let len: u64 = 24;
    
    // Debug: print first char of source
    let first_char: u8 = *source;
    putchar(first_char as i32);
    puts(" = first char of source (should be 'f')");
    
    // Debug: print len
    putchar(48 + (len as i32));
    puts(" = len");
    
    let mut lexer: Lexer = Lexer::new(source, len);
    
    // Debug: print lexer fields
    putchar(48 + (lexer.len as i32));
    puts(" = lexer.len");
    
    // Get tokens one by one
    let tok0: Token = lexer.next_token();
    let tok1: Token = lexer.next_token();
    let tok2: Token = lexer.next_token();
    let tok3: Token = lexer.next_token();
    let tok4: Token = lexer.next_token();
    let tok5: Token = lexer.next_token();
    let tok6: Token = lexer.next_token();
    let tok7: Token = lexer.next_token();
    let tok8: Token = lexer.next_token();
    
    // Print token kinds
    puts("Tokens parsed:");
    
    // Debug: print lexer.pos to confirm tokenization happened
    putchar(48 + (lexer.pos as i32));
    puts(" = final lexer.pos");
    
    // Debug: print token start positions
    putchar(48 + (tok0.start as i32));
    puts(" = tok0.start");
    
    putchar(48 + (tok1.start as i32));
    puts(" = tok1.start");
    if tok2.kind == TokenKind::LParen { puts("  2: LParen"); }
    if tok3.kind == TokenKind::RParen { puts("  3: RParen"); }
    if tok4.kind == TokenKind::LBrace { puts("  4: LBrace"); }
    if tok5.kind == TokenKind::Return { puts("  5: Return"); }
    if tok6.kind == TokenKind::IntLit { puts("  6: IntLit (42)"); }
    if tok7.kind == TokenKind::Semicolon { puts("  7: Semicolon"); }
    if tok8.kind == TokenKind::RBrace { puts("  8: RBrace"); }
    
    puts("=== Token Flow SUCCESS! ===");
    
    return 0;
}
