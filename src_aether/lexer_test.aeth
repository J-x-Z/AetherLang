// AetherLang Lexer Test
// Tests the full lexer functionality

extern "C" {
    fn puts(s: *u8) -> i32;
    fn printf(fmt: *u8) -> i32;
    fn malloc(size: u64) -> *u8;
    fn free(ptr: *u8);
    fn strlen(s: *u8) -> u64;
}

// Forward declare the Lexer API from full_lexer
extern {
    fn Lexer_new(source: *u8, source_len: u64, file_id: u64) -> *void;
    fn Lexer_next_token(result: *void, self: *void) -> void;
    fn Lexer_is_at_end(self: *void) -> bool;
}

fn test_lexer() {
    puts("=== Lexer Integration Test ===" as *u8);
    
    // Simple test source
    let source: *u8 = "fn main() { let x: i32 = 42; }" as *u8;
    let source_len: u64 = strlen(source);
    
    puts("Source:" as *u8);
    printf(source);
    puts("" as *u8);
    puts("" as *u8);
    
    // Create lexer
    puts("Creating lexer..." as *u8);
    let lexer: *void = Lexer_new(source, source_len, 0);
    
    puts("Tokenizing..." as *u8);
    let count: i32 = 0;
    
    while !Lexer_is_at_end(lexer) {
        // Allocate space for token result
        let token: *u8 = malloc(64);  // Token struct size
        Lexer_next_token(token as *void, lexer);
        count = count + 1;
        
        // Just count for now
        if count > 100 {
            break;  // Safety limit
        }
        free(token);
    }
    
    puts("Done!" as *u8);
    printf("Total tokens: " as *u8);
    // Would need printf with %d, just show success for now
    puts("" as *u8);
}

fn main() -> i32 {
    test_lexer();
    puts("Lexer test completed successfully!" as *u8);
    return 0;
}
