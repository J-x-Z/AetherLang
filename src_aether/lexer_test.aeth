// AetherLang Lexer Test Harness
// Tests the self-hosted lexer by tokenizing a simple source file

use core::{printf, exit, malloc, free}
use string::String
use lexer::Lexer
use token::{Token, TokenKind}

/// Entry point
fn main() {
    // Test source code
    let source: *u8 = "fn main() { println(\"Hello!\"); }";
    let source_len: u64 = 33;
    
    // Create lexer
    let mut lexer: Lexer = Lexer::new(source, source_len, 0);
    
    // Tokenize
    let tokens = lexer.tokenize();
    
    // Print results
    printf("Tokenized %d tokens:\n", tokens.len());
    
    let mut i: u64 = 0;
    while i < tokens.len() {
        let tok: &Token = tokens.get(i);
        print_token(tok);
        i = i + 1;
    }
    
    printf("\nâœ… Lexer test passed!\n");
}

/// Print a single token
fn print_token(tok: &Token) {
    let kind_name: *u8 = match tok.kind {
        TokenKind::Fn => "Fn",
        TokenKind::Let => "Let",
        TokenKind::Ident(_) => "Ident",
        TokenKind::IntLit(_) => "IntLit",
        TokenKind::StringLit(_) => "StringLit",
        TokenKind::LParen => "LParen",
        TokenKind::RParen => "RParen",
        TokenKind::LBrace => "LBrace",
        TokenKind::RBrace => "RBrace",
        TokenKind::Semicolon => "Semicolon",
        TokenKind::Eof => "Eof",
        _ => "Other",
    };
    printf("  [%d-%d] %s\n", tok.span.start, tok.span.end, kind_name);
}
